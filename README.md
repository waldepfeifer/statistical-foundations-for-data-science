# ðŸ“Š Statistical Foundations of Data Science

This repository presents a cohesive, practice-driven curriculum that covers the **core statistical pillars of data science**. Designed through five meticulously constructed Jupyter Notebooks, this project highlights practical, simulation-based, and inferential approaches essential for rigorous data analysis and decision-making.

Each notebook aligns with real-world scenarios and academic rigor, making it highly relevant for data science roles in industry, academia, and research.

---

## ðŸš€ Contents

| Notebook | Focus Area | Description |
|----------|------------|-------------|
| `Descriptive_Statistics.ipynb` | **Descriptive Statistics** | Statistical summaries and visualizations of a school performance dataset; includes frequency tables, bar/pie charts, and group comparisons. |
| `Probability.ipynb` | **Probability Theory** | Simulations and theoretical analysis, including the Monty Hall problem to distinguish intuition from formal probability. |
| `Statistical_Inference.ipynb` | **Inferential Statistics** | Hands-on derivation of confidence intervals using simulated proportions with increasing sample sizes and standard error analysis. |
| `Comparing_Samples.ipynb` | **Statistical Comparisons** | Hypothesis testing and sample comparisons in behavioral experiments (note-taking efficacy, animal behavior, game theory scenarios). |
| `Hypothesis_Testing.ipynb` | **Foundations of Hypothesis Testing** | Manual and programmatic derivation of test statistics, confidence intervals, and decisions under uncertainty. |

---

## ðŸ§  Statistical Foundations Covered

This work builds a deep and practical foundation in the following key areas:

### 1. Descriptive Statistics
- Tabulation and summarization techniques
- Measures of central tendency and variability
- Visual exploration using plots (bar, pie, histograms)

### 2. Probability Theory
- Discrete probability simulations
- Conditional probability and independence
- Classical problems (e.g., Monty Hall) with empirical validation

### 3. Inferential Statistics
- Confidence intervals for proportions
- Sample variability and law of large numbers
- Simulation-driven inference at scale (up to 1 million observations)

### 4. Hypothesis Testing
- Null and alternative hypotheses
- Test statistics, p-values, significance levels
- Comparative studies with categorical and continuous variables

### 5. Experimental Design & Analysis
- Randomized studies and observational data
- Between-group comparisons (e.g., ANOVA-like reasoning)
- Real-world case studies with practical implications

---

## ðŸ“Œ Why This Project Stands Out

- âœ… **Simulation-First**: Emphasizes hands-on simulation to validate theory.
- âœ… **End-to-End Analysis**: From data loading to visual storytelling to statistical conclusion.
- âœ… **Diverse Data Contexts**: Includes education, behavioral science, economics, and game theory.
- âœ… **Scalable Techniques**: Introduces scalable computing principles in statistical inference.

---

## ðŸ’¼ Professional Value

This project demonstrates:
- **Data acumen**: Clean data handling, statistical rigor, and reproducibility.
- **Communication skills**: Clear interpretation of results through markdown narratives and visualizations.
- **Problem-solving mindset**: Tackles ambiguous real-world questions using quantitative frameworks.
- **Hiring Advantage**: Shows immediate applicability of statistical knowledge to business, research, and AI modeling.

Whether you're targeting roles in **data science, analytics, quantitative research, or machine learning**, this portfolio demonstrates a rock-solid foundation with high-level statistical maturity.

---

## ðŸ“Ž Requirements

- Python 3.x
- Jupyter Notebook
- NumPy, Pandas, Matplotlib, Seaborn
- (Optional for scaling): `scipy`, `statsmodels`

Install dependencies:
```bash
    pip install numpy pandas matplotlib seaborn
```
---

## ðŸ“‚ Usage

Open each notebook sequentially in Jupyter to follow the curriculum progression:
```bash
    jupyter notebook
```
